# Ollama Extension

Integrates Ollama local AI models with Kortex. Automatically discovers and registers models running on localhost:11434.

## Requirements

- [Ollama](https://ollama.ai/) installed and running locally

## Usage

1. Start Ollama and pull models: `ollama pull <model-name>`
2. Models will automatically appear in Kortex's Ollama provider
3. Select any model to start chatting
